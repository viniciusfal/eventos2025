#!/bin/bash

# Script de Backup Automatizado
# Sistema de Check-in em Eventos
# Vers√£o: 1.0

set -euo pipefail

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configura√ß√µes
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
BACKUP_DIR="/var/backups/eventos"
LOG_FILE="/var/log/eventos-backup.log"
RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Configura√ß√µes AWS S3 (opcional)
AWS_BACKUP_ENABLED=${AWS_BACKUP_ENABLED:-false}
S3_BUCKET=${BACKUP_S3_BUCKET:-""}

# Configura√ß√µes de notifica√ß√£o (opcional)
SLACK_WEBHOOK=${SLACK_WEBHOOK_URL:-""}
DISCORD_WEBHOOK=${DISCORD_WEBHOOK_URL:-""}

# Fun√ß√µes de log
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}" | tee -a "$LOG_FILE"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}" | tee -a "$LOG_FILE"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}" | tee -a "$LOG_FILE"
    send_notification "‚ùå BACKUP FALHOU: $1" "error"
    exit 1
}

info() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}" | tee -a "$LOG_FILE"
}

# Fun√ß√£o para enviar notifica√ß√µes
send_notification() {
    local message="$1"
    local type="${2:-info}"
    
    # Slack notification
    if [[ -n "$SLACK_WEBHOOK" ]]; then
        local color="good"
        [[ "$type" == "error" ]] && color="danger"
        [[ "$type" == "warning" ]] && color="warning"
        
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"attachments\":[{\"color\":\"$color\",\"text\":\"$message\"}]}" \
            "$SLACK_WEBHOOK" >/dev/null 2>&1 || true
    fi
    
    # Discord notification
    if [[ -n "$DISCORD_WEBHOOK" ]]; then
        local embed_color=65280  # Green
        [[ "$type" == "error" ]] && embed_color=16711680    # Red
        [[ "$type" == "warning" ]] && embed_color=16776960  # Yellow
        
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"embeds\":[{\"title\":\"Eventos Backup\",\"description\":\"$message\",\"color\":$embed_color}]}" \
            "$DISCORD_WEBHOOK" >/dev/null 2>&1 || true
    fi
}

# Verificar depend√™ncias
check_dependencies() {
    info "Verificando depend√™ncias para backup..."
    
    command -v docker >/dev/null 2>&1 || error "Docker n√£o est√° instalado"
    command -v gzip >/dev/null 2>&1 || error "gzip n√£o est√° instalado"
    
    # Verificar AWS CLI se backup S3 estiver habilitado
    if [[ "$AWS_BACKUP_ENABLED" == "true" ]]; then
        command -v aws >/dev/null 2>&1 || error "AWS CLI n√£o est√° instalado"
        [[ -n "$S3_BUCKET" ]] || error "S3_BUCKET n√£o est√° configurado"
    fi
    
    log "‚úÖ Depend√™ncias verificadas"
}

# Criar diret√≥rios necess√°rios
setup_directories() {
    info "Configurando diret√≥rios de backup..."
    
    mkdir -p "$BACKUP_DIR/database"
    mkdir -p "$BACKUP_DIR/redis"
    mkdir -p "$BACKUP_DIR/rabbitmq"
    mkdir -p "$BACKUP_DIR/configs"
    mkdir -p "$BACKUP_DIR/logs"
    
    log "‚úÖ Diret√≥rios configurados"
}

# Backup do banco de dados PostgreSQL
backup_database() {
    info "Iniciando backup do banco de dados..."
    
    local backup_file="$BACKUP_DIR/database/postgres_backup_$TIMESTAMP.sql"
    local compressed_file="$backup_file.gz"
    
    # Verificar se o container est√° rodando
    if ! docker ps | grep -q "eventos_postgres_prod"; then
        error "Container PostgreSQL n√£o est√° rodando"
    fi
    
    # Fazer backup
    log "Exportando dados do PostgreSQL..."
    docker exec eventos_postgres_prod pg_dump \
        -U "${DB_USER:-eventos_user}" \
        -d "${DB_NAME:-eventos_db}" \
        --verbose \
        --no-password \
        --format=custom \
        --compress=9 \
        > "$backup_file" || error "Falha no backup do PostgreSQL"
    
    # Comprimir backup
    log "Comprimindo backup do banco de dados..."
    gzip "$backup_file" || error "Falha ao comprimir backup do banco"
    
    # Verificar integridade
    if [[ -f "$compressed_file" ]]; then
        local size=$(stat -f%z "$compressed_file" 2>/dev/null || stat -c%s "$compressed_file" 2>/dev/null)
        log "‚úÖ Backup do banco criado: $compressed_file (${size} bytes)"
        echo "$compressed_file" > "$BACKUP_DIR/latest_db_backup.txt"
    else
        error "Arquivo de backup n√£o foi criado"
    fi
}

# Backup do Redis
backup_redis() {
    info "Iniciando backup do Redis..."
    
    local backup_file="$BACKUP_DIR/redis/redis_backup_$TIMESTAMP.rdb"
    local compressed_file="$backup_file.gz"
    
    # Verificar se o container est√° rodando
    if ! docker ps | grep -q "eventos_redis_prod"; then
        warn "Container Redis n√£o est√° rodando, pulando backup"
        return 0
    fi
    
    # Fazer snapshot do Redis
    log "Criando snapshot do Redis..."
    docker exec eventos_redis_prod redis-cli BGSAVE || warn "Falha ao criar snapshot do Redis"
    
    # Aguardar conclus√£o do snapshot
    sleep 5
    
    # Copiar arquivo RDB
    log "Copiando dados do Redis..."
    docker cp eventos_redis_prod:/data/dump.rdb "$backup_file" || warn "Falha ao copiar dados do Redis"
    
    if [[ -f "$backup_file" ]]; then
        # Comprimir backup
        gzip "$backup_file" || warn "Falha ao comprimir backup do Redis"
        
        local size=$(stat -f%z "$compressed_file" 2>/dev/null || stat -c%s "$compressed_file" 2>/dev/null)
        log "‚úÖ Backup do Redis criado: $compressed_file (${size} bytes)"
        echo "$compressed_file" > "$BACKUP_DIR/latest_redis_backup.txt"
    else
        warn "‚ö†Ô∏è  Backup do Redis n√£o foi criado"
    fi
}

# Backup do RabbitMQ
backup_rabbitmq() {
    info "Iniciando backup do RabbitMQ..."
    
    local backup_file="$BACKUP_DIR/rabbitmq/rabbitmq_backup_$TIMESTAMP.json"
    local compressed_file="$backup_file.gz"
    
    # Verificar se o container est√° rodando
    if ! docker ps | grep -q "eventos_rabbitmq_prod"; then
        warn "Container RabbitMQ n√£o est√° rodando, pulando backup"
        return 0
    fi
    
    # Exportar defini√ß√µes do RabbitMQ
    log "Exportando configura√ß√µes do RabbitMQ..."
    docker exec eventos_rabbitmq_prod rabbitmqctl export_definitions /tmp/definitions.json || warn "Falha ao exportar defini√ß√µes do RabbitMQ"
    
    # Copiar arquivo de defini√ß√µes
    docker cp eventos_rabbitmq_prod:/tmp/definitions.json "$backup_file" || warn "Falha ao copiar defini√ß√µes do RabbitMQ"
    
    if [[ -f "$backup_file" ]]; then
        # Comprimir backup
        gzip "$backup_file" || warn "Falha ao comprimir backup do RabbitMQ"
        
        local size=$(stat -f%z "$compressed_file" 2>/dev/null || stat -c%s "$compressed_file" 2>/dev/null)
        log "‚úÖ Backup do RabbitMQ criado: $compressed_file (${size} bytes)"
        echo "$compressed_file" > "$BACKUP_DIR/latest_rabbitmq_backup.txt"
    else
        warn "‚ö†Ô∏è  Backup do RabbitMQ n√£o foi criado"
    fi
}

# Backup das configura√ß√µes
backup_configs() {
    info "Iniciando backup das configura√ß√µes..."
    
    local backup_file="$BACKUP_DIR/configs/configs_backup_$TIMESTAMP.tar.gz"
    
    # Criar arquivo tar com configura√ß√µes
    log "Comprimindo arquivos de configura√ß√£o..."
    tar -czf "$backup_file" \
        -C "$PROJECT_DIR" \
        configs/ \
        docker-compose.production.yml \
        .env.production.example \
        scripts/ \
        2>/dev/null || warn "Alguns arquivos de configura√ß√£o podem n√£o existir"
    
    if [[ -f "$backup_file" ]]; then
        local size=$(stat -f%z "$backup_file" 2>/dev/null || stat -c%s "$backup_file" 2>/dev/null)
        log "‚úÖ Backup das configura√ß√µes criado: $backup_file (${size} bytes)"
        echo "$backup_file" > "$BACKUP_DIR/latest_config_backup.txt"
    else
        warn "‚ö†Ô∏è  Backup das configura√ß√µes n√£o foi criado"
    fi
}

# Backup dos logs
backup_logs() {
    info "Iniciando backup dos logs..."
    
    local backup_file="$BACKUP_DIR/logs/logs_backup_$TIMESTAMP.tar.gz"
    local logs_dir="/var/log"
    
    # Criar backup dos logs se existirem
    if [[ -d "$logs_dir" ]]; then
        log "Comprimindo arquivos de log..."
        find "$logs_dir" -name "*eventos*" -type f -mtime -7 | \
            tar -czf "$backup_file" -T - 2>/dev/null || warn "Nenhum log encontrado para backup"
        
        if [[ -f "$backup_file" ]]; then
            local size=$(stat -f%z "$backup_file" 2>/dev/null || stat -c%s "$backup_file" 2>/dev/null)
            log "‚úÖ Backup dos logs criado: $backup_file (${size} bytes)"
            echo "$backup_file" > "$BACKUP_DIR/latest_logs_backup.txt"
        fi
    else
        warn "‚ö†Ô∏è  Diret√≥rio de logs n√£o encontrado"
    fi
}

# Upload para S3 (se configurado)
upload_to_s3() {
    if [[ "$AWS_BACKUP_ENABLED" != "true" ]]; then
        info "Backup S3 n√£o est√° habilitado, pulando upload"
        return 0
    fi
    
    info "Iniciando upload para S3..."
    
    local s3_prefix="eventos-backup/$(date +%Y/%m/%d)"
    
    # Upload dos backups
    find "$BACKUP_DIR" -name "*_$TIMESTAMP.*" -type f | while read -r file; do
        local filename=$(basename "$file")
        local s3_key="$s3_prefix/$filename"
        
        log "Uploading $filename para S3..."
        aws s3 cp "$file" "s3://$S3_BUCKET/$s3_key" || warn "Falha no upload de $filename"
    done
    
    log "‚úÖ Upload para S3 conclu√≠do"
}

# Limpeza de backups antigos
cleanup_old_backups() {
    info "Limpando backups antigos (mais de $RETENTION_DAYS dias)..."
    
    # Limpeza local
    find "$BACKUP_DIR" -type f -mtime +$RETENTION_DAYS -delete 2>/dev/null || true
    
    # Limpeza no S3 (se configurado)
    if [[ "$AWS_BACKUP_ENABLED" == "true" ]]; then
        local cutoff_date=$(date -d "$RETENTION_DAYS days ago" +%Y-%m-%d)
        log "Limpando backups S3 anteriores a $cutoff_date..."
        
        aws s3api list-objects-v2 \
            --bucket "$S3_BUCKET" \
            --prefix "eventos-backup/" \
            --query "Contents[?LastModified<='$cutoff_date'].Key" \
            --output text | \
        while read -r key; do
            [[ -n "$key" && "$key" != "None" ]] && aws s3 rm "s3://$S3_BUCKET/$key" || true
        done 2>/dev/null || warn "Falha na limpeza do S3"
    fi
    
    log "‚úÖ Limpeza conclu√≠da"
}

# Verificar integridade dos backups
verify_backups() {
    info "Verificando integridade dos backups..."
    
    local error_count=0
    
    # Verificar backup do banco
    if [[ -f "$BACKUP_DIR/latest_db_backup.txt" ]]; then
        local db_backup=$(cat "$BACKUP_DIR/latest_db_backup.txt")
        if [[ -f "$db_backup" ]]; then
            log "‚úÖ Backup do banco verificado: $(basename "$db_backup")"
        else
            warn "‚ö†Ô∏è  Backup do banco n√£o encontrado"
            ((error_count++))
        fi
    fi
    
    # Verificar outros backups...
    for service in redis rabbitmq config logs; do
        local latest_file="$BACKUP_DIR/latest_${service}_backup.txt"
        if [[ -f "$latest_file" ]]; then
            local backup_file=$(cat "$latest_file")
            if [[ -f "$backup_file" ]]; then
                log "‚úÖ Backup do $service verificado: $(basename "$backup_file")"
            else
                warn "‚ö†Ô∏è  Backup do $service n√£o encontrado"
                ((error_count++))
            fi
        fi
    done
    
    if [[ $error_count -gt 0 ]]; then
        warn "‚ö†Ô∏è  $error_count backup(s) com problemas"
        return 1
    else
        log "‚úÖ Todos os backups verificados com sucesso"
        return 0
    fi
}

# Relat√≥rio de backup
generate_report() {
    info "Gerando relat√≥rio de backup..."
    
    local report_file="$BACKUP_DIR/backup_report_$TIMESTAMP.txt"
    
    {
        echo "========================================="
        echo "RELAT√ìRIO DE BACKUP - $(date)"
        echo "========================================="
        echo
        echo "Timestamp: $TIMESTAMP"
        echo "Diret√≥rio: $BACKUP_DIR"
        echo "Reten√ß√£o: $RETENTION_DAYS dias"
        echo "AWS S3: $AWS_BACKUP_ENABLED"
        echo
        echo "ARQUIVOS CRIADOS:"
        echo "-----------------"
        
        find "$BACKUP_DIR" -name "*_$TIMESTAMP.*" -type f | while read -r file; do
            local size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null)
            echo "$(basename "$file"): ${size} bytes"
        done
        
        echo
        echo "ESPA√áO UTILIZADO:"
        echo "-----------------"
        du -sh "$BACKUP_DIR" 2>/dev/null || echo "Erro ao calcular espa√ßo"
        
        echo
        echo "STATUS DOS SERVI√áOS:"
        echo "--------------------"
        docker ps --format "table {{.Names}}\t{{.Status}}" | grep eventos || echo "Nenhum container encontrado"
        
    } > "$report_file"
    
    log "‚úÖ Relat√≥rio gerado: $report_file"
    
    # Enviar relat√≥rio por notifica√ß√£o
    local summary="üîÑ Backup conclu√≠do em $(date). Verifique $report_file para detalhes."
    send_notification "$summary" "info"
}

# Fun√ß√£o principal
main() {
    log "üîÑ Iniciando processo de backup automatizado"
    log "üìÖ Data: $(date)"
    log "‚è∞ Timestamp: $TIMESTAMP"
    
    check_dependencies
    setup_directories
    
    # Executar backups
    backup_database
    backup_redis
    backup_rabbitmq
    backup_configs
    backup_logs
    
    # Upload e limpeza
    upload_to_s3
    cleanup_old_backups
    
    # Verifica√ß√£o e relat√≥rio
    if verify_backups; then
        generate_report
        log "üéâ Processo de backup conclu√≠do com sucesso!"
        send_notification "‚úÖ Backup automatizado conclu√≠do com sucesso!" "info"
    else
        warn "‚ö†Ô∏è  Backup conclu√≠do com alguns problemas. Verifique os logs."
        send_notification "‚ö†Ô∏è Backup conclu√≠do com problemas. Verifique os logs." "warning"
    fi
}

# Verificar argumentos
case "${1:-backup}" in
    "backup"|"")
        main
        ;;
    "restore")
        echo "Funcionalidade de restore ainda n√£o implementada"
        echo "Para restaurar manualmente:"
        echo "1. Pare os servi√ßos: docker-compose -f docker-compose.production.yml down"
        echo "2. Restaure o banco: docker exec -i postgres_container pg_restore -U user -d database < backup.sql"
        echo "3. Restaure outros servi√ßos conforme necess√°rio"
        echo "4. Reinicie os servi√ßos: docker-compose -f docker-compose.production.yml up -d"
        ;;
    "verify")
        verify_backups
        ;;
    "cleanup")
        cleanup_old_backups
        ;;
    "report")
        generate_report
        ;;
    *)
        echo "Uso: $0 [backup|restore|verify|cleanup|report]"
        echo
        echo "Comandos dispon√≠veis:"
        echo "  backup   - Executar backup completo (padr√£o)"
        echo "  restore  - Instru√ß√µes para restaurar backup"
        echo "  verify   - Verificar integridade dos backups"
        echo "  cleanup  - Limpar backups antigos"
        echo "  report   - Gerar relat√≥rio dos backups"
        exit 1
        ;;
esac